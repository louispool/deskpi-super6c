# Values for the fluentbit HELM chart
# https://github.com/fluent/helm-charts/blob/main/charts/fluent-bit/values.yaml
---
service:
  type: ClusterIP
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "2020"
    prometheus.io/path: "/api/v1/metrics/prometheus"

resources:
  limits:
    memory: 200Mi
    cpu: 200m
  requests:
    memory: 100Mi
    cpu: 100m

rbac:
  create: true
  nodeAccess: true
  eventsAccess: false

# Set the flush time in `seconds.nanoseconds`.
# The engine loop uses a Flush timeout to define when it's required to flush the records
# ingested by input plugins through the defined output plugins.
flush: 1

# Set the logging verbosity level. Allowed values are: off, error, warn, info, debug, and trace.
# Values are cumulative. If debug is set, it will include error, warning, info, and debug
logLevel: info

# TCP Port for the HTTP Server.
metricsPort: 2020

# Volumes and mounts for Lua scripts
extraVolumeMounts:
  - name: lua-scripts
    mountPath: /fluent-bit/scripts
    readOnly: true

extraVolumes:
  - name: lua-scripts
    configMap:
      name: fluentbit-lua-scripts

# https://docs.fluentbit.io/manual/administration/configuring-fluent-bit/classic-mode/configuration-file
config:
  # https://docs.fluentbit.io/manual/pipeline/inputs
  inputs: |
    # https://docs.fluentbit.io/manual/pipeline/inputs/tail
    # Collect logs from container log files in the /var/log/containers directory
    [INPUT]
        name             tail
        path             /var/log/containers/*.log
        multiline.parser docker, cri
        tag              kube.*
        refresh_interval 5
        mem_buf_limit    20MB
        skip_long_lines  on
        db               /var/log/flb_kube.db

    # https://docs.fluentbit.io/manual/pipeline/inputs/systemd
    # Collect logs from systemd journal for system services
    [INPUT]
        name              systemd
        tag               sys.*
        systemd_filter    _SYSTEMD_UNIT=k3s.service
        systemd_filter    _SYSTEMD_UNIT=ssh.service
        systemd_filter    _SYSTEMD_UNIT=cron.service
        systemd_filter    _SYSTEMD_UNIT=dnsmasq.service
        systemd_filter    _SYSTEMD_UNIT=dbus.service
        read_from_tail    on
        max_entries       5000
        strip_underscores on
        db                /var/log/flb_systemd.db

  # https://docs.fluentbit.io/manual/pipeline/filters
  filters: |
    # https://docs.fluentbit.io/manual/pipeline/filters/kubernetes
    # Enrich logs with Kubernetes metadata
    [FILTER]
        name                  kubernetes
        match                 kube.*
        buffer_size           256k
        merge_log             on
        keep_log              off
        labels                on
        annotations           off
        namespace_labels      off
        namespace_annotations off

    # Extract Kubernetes metadata into top-level fields
    # k8s_namespace, k8s_pod, k8s_app, k8s_container and log_prefix
    [FILTER]
        name      lua
        match     kube.*
        script    /fluent-bit/scripts/extract_kubernetes.lua
        call      extract_kubernetes

    # Filter out overly verbose logs from kube-probe
    [FILTER]
        name      grep
        match     kube.*
        exclude   k8s_container kube-probe

    # Remove unnecessary fields from the logs
    [FILTER]
        name      modify
        match     kube.*
        remove    kubernetes
        remove    _p

    # For debugging purposes, prints all kube logs to stdout
    #[FILTER]
    #    name      lua
    #    match     kube.*
    #    script    /fluent-bit/scripts/pretty_print.lua
    #    call      pretty_print

  # https://docs.fluentbit.io/manual/pipeline/outputs
  outputs: |
    # Send logs to OpenSearch (see https://docs.fluentbit.io/manual/pipeline/outputs/elasticsearch)
    [OUTPUT]
        name               opensearch
        match              kube.*
        host               {{ opensearch_cluster_name }}-{{ opensearch_node_group }}.{{ k3s_opensearch_namespace }}.svc.cluster.local
        port               9200
        http_user          {{ opensearch_logger_user}}
        http_passwd        {{ opensearch_logger_passwd }}
        index              $log_prefix
        tls                off
        tls.verify         off

        # Enabling the logstash format will override the index name
        # for more information see https://docs.fluentbit.io/manual/data-pipeline/outputs/opensearch
        logstash_format     off
        logstash_prefix_key $log_prefix

        # These are required to avoid issues with OpenSearch 2.x
        suppress_type_name on
        replace_dots       on

        # Set to 'on' to enable error tracing in the logs
        trace_error        off
        trace_output       off

    [OUTPUT]
        name                opensearch
        match               sys.*
        host                {{ opensearch_cluster_name }}-{{ opensearch_node_group }}.{{ k3s_opensearch_namespace }}.svc.cluster.local
        port                9200
        http_user           {{ opensearch_logger_user}}
        http_passwd         {{ opensearch_logger_passwd }}
        index               system-logs
        tls                 off
        tls.verify          off

        # Enabling the logstash format will override the index name
        # for more information see https://docs.fluentbit.io/manual/data-pipeline/outputs/opensearch
        logstash_format     off
        logstash_prefix     system-logs

        # These are required to avoid issues with OpenSearch 2.x
        suppress_type_name  on
        replace_dots        on

        # Set to 'on' to enable error tracing in the logs
        trace_error         off
        trace_output        off

serviceMonitor:
  enabled: true
  namespace: {{ k3s_monitoring_namespace }}
  interval: 10s
  scrapeTimeout: 10s
  # Metric relabel configs to apply to samples before ingestion.
  metricRelabelings:
    - sourceLabels: [__meta_kubernetes_service_label_cluster]
      targetLabel: cluster
      action: replace
  # Relabel configs to apply to samples after ingestion.
  relabelings:
    - sourceLabels: [ __meta_kubernetes_namespace ]
      targetLabel: namespace
      action: replace
    - sourceLabels: [ __meta_kubernetes_pod_name ]
      targetLabel: pod
      action: replace
    - sourceLabels: [ __meta_kubernetes_pod_container_name ]
      targetLabel: container
      action: replace
    - sourceLabels: [ __meta_kubernetes_pod_node_name ]
      targetLabel: nodename
      action: replace
    - sourceLabels: [ __meta_kubernetes_service_name ]
      targetLabel: service
      action: replace

prometheusRule:
  enabled: true
  namespace: {{ k3s_monitoring_namespace }}
  additionalLabels:
    release: kube-prometheus-stack
    prometheus: fluentbit
    role: alert-rules
  rules:{% raw %}
    - alert: NoOutputBytesProcessed
      expr: rate(fluentbit_output_proc_bytes_total[5m]) == 0
      for: 15m
      labels:
        severity: warning
      annotations:
        summary: Fluent Bit output is not processing data
        message: |
          Fluent Bit instance {{ $labels.instance }} output plugin {{ $labels.name }} has not processed any bytes for 15 minutes.{% endraw %}

dashboards:
  enabled: true
  namespace: {{ k3s_monitoring_namespace }}
  # These fields are used to tell Grafana's sidecar dashboard importer to pick up dashboards from ConfigMaps or Secrets that match a specific label.
  # You can check  what the label and value should by running `kubectl get deployment -n monitoring -l app.kubernetes.io/name=grafana -o yaml | grep -A 1 LABEL`
  labelKey: grafana_dashboard
  labelValue: "1"